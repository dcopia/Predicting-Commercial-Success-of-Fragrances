# -*- coding: utf-8 -*-
"""FragrancesSuccess.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pR0BX_x-prjE5n03EYGJbdaoKlsIoy56

# Predicting Commercial Success of Fragrances
## A Machine Learning Approach Using Olfactory and Market Features

This notebook demonstrates how to predict the commercial success of fragrances using machine learning techniques applied to fragrance characteristics and market data.

**Objective**: Can we predict commercial success based on fragrance features like accords, brand, perfumer, and olfactory complexity?

# 1. Data Loading and Initial Exploration
"""

import kagglehub
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler

!pip install flaml

path = kagglehub.dataset_download("olgagmiufana1/fragrantica-com-fragrance-dataset")

print("Path to dataset files:", path)

file_path = '/kaggle/input/fragrantica-com-fragrance-dataset/fra_cleaned.csv'

df = pd.read_csv(file_path, encoding='latin1', on_bad_lines='skip', sep=';')

print("DataFrame Head:")
display(df.head())

print("\nDataFrame Info:")
df.info()

"""- **URL**: link to the fragrance’s page
- **Perfume**: fragrance name  
- **Brand**: standardized brand names  
- **Country**: standardized country names for consistent analysis  
- **Gender**: cleaned and unified marketing gender categories
- **Rating Value**: cleaned numeric ratings
- **Rating Count**: standardized number of ratings  
- **Year**: launch year
- **Top Notes**: parsed and standardized top notes  
- **Middle Notes**: parsed and standardized middle notes  
- **Base Notes**: parsed and standardized base notes  
- **Perfumer1, Perfumer2**: standardized and separated perfumer names  
- **Main Accord 1–5**: cleaned and separated into distinct scent families  

---

### Notes vs. Accords
- **Notes**: Individual fragrance components (e.g., bergamot, jasmine, vanilla). They are usually categorized as **top, middle (heart), and base notes**, depending on when they appear in the fragrance’s lifecycle.  
- **Accords**: Harmonized blends of multiple notes that create a new, distinct impression (e.g., *woody*, *floral*, *oriental*). While notes are ingredients, accords represent the **overall olfactory effect**.  

"""

# Check for missing values
print("\nMissing Values:")
display(df.isnull().sum())

"""During preprocessing, different imputation strategies were tested for handling missing values in the Year variable. Using the median year (2015) was the simplest approach, but it artificially concentrated a large number of perfumes in a single year, thus distorting the temporal distribution. To avoid this bias, the missing years were instead imputed through a random assignment weighted by the empirical distribution of existing years. This strategy preserved the overall shape of the dataset’s temporal distribution and provided a more realistic representation of the data."""

# Year: fill missing values randomly based on distribution
year_dist = df['Year'].dropna().astype(int).value_counts(normalize=True)
n_missing = df['Year'].isna().sum()
imputed = np.random.choice(year_dist.index, size=n_missing, p=year_dist.values)
df.loc[df['Year'].isna(), 'Year'] = imputed
df['Year'] = df['Year'].astype('int32')

# Rating Count: convert to int
df['Rating Count'] = df['Rating Count'].astype('int32')

# Rating Value: replace comma and convert to float
df['Rating Value'] = df['Rating Value'].astype(str).str.replace(",", ".", regex=False)
df['Rating Value'] = df['Rating Value'].astype('float32')

print(f"Missing years filled: {n_missing}")
df.info()

"""# 2. Data Exploration"""

# Display descriptive statistics for numerical columns
print("Descriptive Statistics:")
display(df.describe())

# Set the style for the plots
sns.set_style("whitegrid")

# Distribution of Gender
plt.figure(figsize=(8, 5))
sns.countplot(data=df, x='Gender', order=df['Gender'].value_counts().index)
plt.title('Distribution of Gender')
plt.xlabel('Gender')
plt.ylabel('Count')
plt.show()

# Distribution of Top 10 Brands
plt.figure(figsize=(12, 6))
top_brands = df['Brand'].value_counts().nlargest(10).index
sns.countplot(data=df, y='Brand', order=top_brands)
plt.title('Top 10 Brands by Count')
plt.xlabel('Count')
plt.ylabel('Brand')
plt.show()

# Distribution of Top 10 Countries
plt.figure(figsize=(12, 6))
top_countries = df['Country'].value_counts().nlargest(10).index
sns.countplot(data=df, y='Country', order=top_countries)
plt.title('Top 10 Countries by Count')
plt.xlabel('Count')
plt.ylabel('Country')
plt.show()

# Distribution of Top 10 Main Accords (combining all mainaccord columns)
# First, stack the mainaccord columns to count frequencies
main_accords = df[['mainaccord1', 'mainaccord2', 'mainaccord3', 'mainaccord4', 'mainaccord5']].stack().reset_index(drop=True)

plt.figure(figsize=(12, 6))
top_accords = main_accords.value_counts().nlargest(10).index
sns.countplot(x=main_accords, order=top_accords)
plt.title('Top 10 Main Accords by Count')
plt.xlabel('Main Accord')
plt.ylabel('Count')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Year counts
year_counts = df['Year'].value_counts().sort_index()

# Rating Value
plt.hist(df['Rating Value'], bins=50)
plt.title('Distribution of Rating Value')
plt.xlabel('Rating Value')
plt.ylabel('Frequency')
plt.axvline(df['Rating Value'].mean(), color='red', linestyle='--', label=f'Mean: {df["Rating Value"].mean():.2f}')
plt.legend()
plt.show()

# Rating Count
plt.hist(df['Rating Count'], bins=50)
plt.title('Distribution of Rating Count')
plt.xlabel('Rating Count')
plt.ylabel('Frequency')
plt.show()

# Year trend
plt.plot(year_counts.index, year_counts.values, marker='o')
plt.title('Perfumes Released per Year')
plt.xlabel('Year')
plt.ylabel('Count')
plt.show()

# Scatter plot
plt.scatter(df['Rating Value'], df['Rating Count'], alpha=0.5, s=10)
plt.title('Rating Value vs Rating Count')
plt.xlabel('Rating Value')
plt.ylabel('Rating Count')
plt.show()

sns.set_style("whitegrid")

# Rating Count (log scale)
plt.hist(np.log1p(df['Rating Count']), bins=50)
plt.title('Distribution of Rating Count (Log Scale)')
plt.xlabel('Log(Rating Count + 1)')
plt.ylabel('Frequency')
plt.show()

# Scatter Rating Value vs Rating Count (log y)
plt.scatter(df['Rating Value'], np.log1p(df['Rating Count']), alpha=0.5, s=10)
plt.title('Rating Value vs Rating Count (Log)')
plt.xlabel('Rating Value')
plt.ylabel('Log(Rating Count + 1)')
plt.show()

"""# 3. Defining Commercial Success

We create a composite success metric that balances quality (user ratings) with popularity (number of ratings):

**Success_Score = 0.8 × Normalized_Rating + 0.2 × Normalized_Log_Count**

This approach prioritizes quality (80%) while acknowledging that commercial success requires market visibility (20%).
"""

scaler = MinMaxScaler()

# Normalize Rating Value
df['Rating_Normalized'] = scaler.fit_transform(df[['Rating Value']])

# Log-transform and normalize Rating Count
df['Log_Count'] = np.log1p(df['Rating Count'])
df['Log_Count_Norm'] = scaler.fit_transform(df[['Log_Count']])

# Weighted success score
df['Success_Score'] = 0.8 * df['Rating_Normalized'] + 0.2 * df['Log_Count_Norm']

print("Range:", df['Success_Score'].min(), "-", df['Success_Score'].max())
print("Mean:", df['Success_Score'].mean())

"""# 4. Feature Engineering

We'll create features across multiple dimensions:
- **Temporal**: Age, recent/vintage indicators
- **Brand**: Portfolio size, average rating, reputation metrics
- **Geographic**: Regional groupings and country-level features
- **Perfumer**: Experience and historical success metrics
- **Olfactory**: Note complexity and accord features

### Temporal Features

- **Age**: Calculated as the difference between the current year (2024) and the launch year of the perfume. This feature captures how long a fragrance has been on the market.  
- **Is_Recent**: Binary indicator that equals 1 if a fragrance was launched within the last 5 years. It highlights **new releases** that may benefit from current marketing trends or consumer interest.  
- **Is_Vintage**: Binary indicator that equals 1 if a fragrance is 20 years old or more. It identifies **long-established perfumes**, which might reflect brand heritage, loyal consumer bases, or timeless popularity.
"""

current_year = 2024
df['Age'] = current_year - df['Year']
df['Is_Recent'] = (df['Age'] <= 5).astype(int)
df['Is_Vintage'] = (df['Age'] >= 20).astype(int)

print(df[['Age','Is_Recent','Is_Vintage']].head())

"""### Brand Features

- **Brand_Portfolio_Size**: Number of perfumes released by the brand. This reflects the **breadth of the brand’s product line**.  
- **Brand_Avg_Rating**: Average user rating across the brand’s perfumes. It captures the **perceived quality** of the brand.  
- **Brand_Avg_Popularity**: Average number of ratings received by the brand’s perfumes. This reflects the **overall consumer engagement** with the brand.  
- **Brand_Years_Active**: Calculated as the difference between the earliest and most recent perfume release year. It measures the **brand’s longevity in the market**.
"""

brand_stats = df.groupby('Brand').agg({
    'Rating Value': ['count', 'mean'],   # Brand_Portfolio_Size (count) + Brand_Avg_Rating (mean)
    'Rating Count': 'mean'               # Brand_Avg_Popularity (mean of ratings count)
}).round(3)

brand_stats.columns = [
    'Brand_Portfolio_Size',   # Number of perfumes
    'Brand_Avg_Rating',       # Avg. rating
    'Brand_Avg_Popularity'    # Avg. rating count
]

df = df.merge(brand_stats, left_on='Brand', right_index=True, how='left')

# Brand experience → Brand_Years_Active (longevity in the market)
brand_exp = df.groupby('Brand')['Year'].agg(['min', 'max'])
brand_exp['Brand_Years_Active'] = brand_exp['max'] - brand_exp['min'] + 1

df = df.merge(brand_exp[['Brand_Years_Active']], left_on='Brand', right_index=True, how='left')

print(df[['Brand', 'Brand_Portfolio_Size', 'Brand_Avg_Rating',
          'Brand_Avg_Popularity', 'Brand_Years_Active']].head())

"""### Geographical Features
- **Country_Avg_Rating**: Average user rating of perfumes produced in each
"""

# Geographical features

# Unique countries list
unique_countries = df['Country'].unique().tolist()
print("Unique values in 'Country':")
display(unique_countries)

# Number of unique countries
num_unique_countries = len(unique_countries)
print(f"\nNumber of unique values in 'Country': {num_unique_countries}")

# Plot: perfumes per country (Top 15 for readability)
plt.figure(figsize=(12,6))
top_countries = df['Country'].value_counts().nlargest(15)
sns.barplot(x=top_countries.values, y=top_countries.index, palette="viridis")
plt.title("Top 15 Countries by Number of Perfumes")
plt.xlabel("Number of Perfumes")
plt.ylabel("Country")
plt.show()

# Country-level statistics: average rating and average success score
country_stats = df.groupby('Country').agg({
    'Rating Value': 'mean',
    'Success_Score': 'mean'
}).round(3)

country_stats.columns = ['Country_Avg_Rating', 'Country_Avg_Success']

# Merge back to df
df = df.merge(country_stats, left_on='Country', right_index=True, how='left')

print("DataFrame Head with new geographical features:")
display(df[['Country', 'Country_Avg_Rating', 'Country_Avg_Success']].head())

"""### Perfumer Features
- **Has_Known_Perfumer**: Binary indicator equal to 1 if the perfumer is known, 0 otherwise. This helps capture the influence of **reputation** versus anonymity.  
- **Has_Two_Perfumers**: Binary indicator equal to 1 if the fragrance has two perfumers. It reflects **collaborative creations**, which may influence complexity or brand positioning.  
- **Perfumer_Portfolio_Size**: Number of perfumes attributed to each perfumer. It measures their **experience and presence** in the industry.  
- **Perfumer_Avg_Rating**: Average rating across a perfumer’s portfolio, used as a proxy for **quality reputation**.  
- **Perfumer_Avg_Success**: Average success score (80/20 metric) across the perfumer’s portfolio, representing **market performance**.  
"""

# 1. Flag if the perfumer is known (not 'unknown')
df['Has_Known_Perfumer'] = (df['Perfumer1'] != 'unknown').astype(int)

# 2. Flag if the perfume has two perfumers
df['Has_Two_Perfumers'] = df['Perfumer2'].notna().astype(int)

# 3. Compute stats for known perfumers
perfumer_stats = df[df['Perfumer1'] != 'unknown'].groupby('Perfumer1').agg({
    'Rating Value': ['count', 'mean'],        # Portfolio size + avg rating
    'Success_Score': 'mean'             # Avg success score
}).round(3)

perfumer_stats.columns = [
    'Perfumer_Portfolio_Size',   # Number of perfumes created
    'Perfumer_Avg_Rating',       # Average rating
    'Perfumer_Avg_Success'       # Average success score
]

# 4. Merge stats back to main DataFrame
df = df.merge(perfumer_stats, left_on='Perfumer1', right_index=True, how='left')

# 5. Fill NaN with 0 for unknown perfumers
for col in ['Perfumer_Portfolio_Size', 'Perfumer_Avg_Rating', 'Perfumer_Avg_Success']:
    df[col] = df[col].fillna(0)

print("DataFrame Head with new perfumer features:")
display(df[['Perfumer1', 'Perfumer2', 'Has_Known_Perfumer', 'Has_Two_Perfumers',
            'Perfumer_Portfolio_Size', 'Perfumer_Avg_Rating', 'Perfumer_Avg_Success']].head())

"""### Olfactory Complexity Features

- **Top_Notes_Count**: Number of notes listed in the top layer of the fragrance.  
- **Middle_Notes_Count**: Number of notes listed in the heart (middle) layer.  
- **Base_Notes_Count**: Number of notes listed in the base layer.  
- **Total_Notes_Count**: Sum of all notes across the three layers.
- **Accord_Profume**: One Hot of top 40 frequent accords
"""

# Function to count notes in a string (comma-separated)
def count_notes(note_string):
    if pd.isna(note_string):
        return 0
    return len([note.strip() for note in str(note_string).split(',') if note.strip()])

# Count notes for each layer
df['Top_Notes_Count'] = df['Top'].apply(count_notes)        # Number of top notes
df['Middle_Notes_Count'] = df['Middle'].apply(count_notes)  # Number of middle/heart notes
df['Base_Notes_Count'] = df['Base'].apply(count_notes)      # Number of base notes

# Total notes (overall complexity)
df['Total_Notes_Count'] = (
    df['Top_Notes_Count'] + df['Middle_Notes_Count'] + df['Base_Notes_Count']
)

print("DataFrame Head with new olfactory complexity features:")
display(df[['Top', 'Middle', 'Base',
            'Top_Notes_Count', 'Middle_Notes_Count', 'Base_Notes_Count',
            'Total_Notes_Count']].head())

"""**Accords Features**

"""

# Collect all accords into a single Series
accords = df[['mainaccord1','mainaccord2','mainaccord3','mainaccord4','mainaccord5']].stack()

# Get top 40 most frequent accords
top_40_accords = accords.value_counts().nlargest(40).index.tolist()

print("Top 40 accords:")
print(top_40_accords)

# Function to check if a perfume has a given accord
def has_accord(row, accord):
    return int(accord in [
        row['mainaccord1'], row['mainaccord2'], row['mainaccord3'],
        row['mainaccord4'], row['mainaccord5']
    ])

# Create one-hot encoded columns for the top 40 accords
for acc in top_40_accords:
    df[f'Accord_{acc}'] = df.apply(lambda row: has_accord(row, acc), axis=1)

print("DataFrame with one-hot encoded top accords:")
display(df.head())

"""#5. Preprocessing

"""

# One-Hot Encoding del Gender
gender_dummies = pd.get_dummies(df['Gender'], prefix='Gender')

# Unisci le nuove colonne al dataframe
df = pd.concat([df, gender_dummies], axis=1)

print("DataFrame head with one-hot encoded gender features:")
display(df[['Gender', 'Gender_men', 'Gender_unisex', 'Gender_women']].head())

# Display all column names to see the new features
print("DataFrame Columns:")
print(df.columns.tolist())

# Display DataFrame info
print("\nDataFrame Info:")
df.info()

# Convert float64 → float32 and int64 → int32
for col in df.select_dtypes(include=['float64']).columns:
    df[col] = df[col].astype('float32')

for col in df.select_dtypes(include=['int64']).columns:
    df[col] = df[col].astype('int32')

# Show DataFrame info after conversion
print("DataFrame info after dtype conversion:")
df.info()

"""**Selecting features**"""

# 1. Select accord features automatically
accord_features = [col for col in df.columns if col.startswith("Accord_")]
print("Number of accord features:", len(accord_features))

# 2. Define manual feature list
features_for_modeling = [

    # Temporal
    "Year", "Age", "Is_Recent", "Is_Vintage",

    # Brand
    "Brand_Portfolio_Size", "Brand_Avg_Rating",
    "Brand_Avg_Popularity", "Brand_Years_Active",

    # Country/Region
    "Country_Avg_Rating", "Country_Avg_Success",

    # Perfumer
    "Has_Known_Perfumer", "Has_Two_Perfumers",
    "Perfumer_Portfolio_Size", "Perfumer_Avg_Rating", "Perfumer_Avg_Success",

    # Olfactory Complexity
    "Top_Notes_Count", "Middle_Notes_Count", "Base_Notes_Count", "Total_Notes_Count",

    # Gender
    "Gender_men", "Gender_unisex", "Gender_women"
]

# 3. Add accords to feature list
features_for_modeling.extend(accord_features)

# 4. Create engineered DataFrame
df_eng = df[features_for_modeling].copy()

# 5. Display check
print("\nEngineered DataFrame Head:")
display(df_eng.head())

print("\nEngineered DataFrame Info:")
df_eng.info()

# Correlation of features with target
df_combined = df_eng.copy()
df_combined['Success_Score'] = df['Success_Score']

corr = df_combined.corr()['Success_Score'].sort_values(ascending=False)

print("Correlation with Success_Score:")
display(corr)

# Bar plot
plt.figure(figsize=(10, 8))
sns.barplot(x=corr.values, y=corr.index, palette='viridis')
plt.title('Feature Correlation with Success_Score')
plt.xlabel('Correlation Coefficient')
plt.ylabel('Feature')
plt.show()

"""**Why "Year" Matters**

- **Correlation**: shows a small negative trend (newer perfumes score slightly lower).  
- **Feature Importance**: trees capture non-linear effects →  
  - Recent = hype  
  - Vintage = prestige  
- **Key point**: low correlation doesn’t mean low importance; Year helps separate success patterns.  

"""

# Correlation matrix only on engineered features (numeric)
corr_matrix = df_eng.corr()

# Heatmap (compact visualization)
plt.figure(figsize=(14,10))
sns.heatmap(corr_matrix, cmap='coolwarm', center=0)
plt.title('Correlation Matrix of Engineered Features')
plt.show()

# Top correlated pairs (excluding self-correlation)
abs_corr = corr_matrix.abs()
upper = abs_corr.where(~np.tril(np.ones(abs_corr.shape)).astype(bool))
top_corr = upper.stack().sort_values(ascending=False).head(20)

print("\nTop 20 correlated engineered feature pairs:")
display(top_corr)

"""***Drop Collinear Features***"""

# Correlation matrix (absolute values)
corr_matrix = df_eng.corr().abs()

# Threshold for collinearity
threshold = 0.80

# Set to store columns to drop
to_drop = set()
dropped_pairs = []

# Iterate over the upper triangular matrix
for i in range(len(corr_matrix.columns)):
    for j in range(i):
        if corr_matrix.iloc[i, j] > threshold:
            col_to_drop = corr_matrix.columns[i]   # drop the "later" one
            col_keep = corr_matrix.columns[j]
            to_drop.add(col_to_drop)
            dropped_pairs.append((col_keep, col_to_drop, corr_matrix.iloc[i, j]))

# Print dropped pairs
print("Dropped feature pairs (keep, drop, correlation):")
for keep, drop, corr in dropped_pairs:
    print(f"Keep: {keep:25s} | Drop: {drop:25s} | Corr: {corr:.3f}")

# Drop features
df_eng_reduced = df_eng.drop(columns=to_drop)

print("\nFeatures dropped:", list(to_drop))
print("Shape before:", df_eng.shape)
print("Shape after:", df_eng_reduced.shape)

"""**Standardizing** for linear regression"""

# Copy to avoid overwriting
df_scaled = df_eng_reduced.copy()

# Select numeric columns
numeric_cols = df_scaled.select_dtypes(include=['float32','int32']).columns

# Exclude binary features (0/1)
binary_like = [col for col in numeric_cols if df_scaled[col].nunique() <= 2]

# Exclude one-hot encoded accords
accord_cols = [col for col in numeric_cols if col.startswith("Accord_")]

# Final list of columns to scale
cols_to_scale = [col for col in numeric_cols if col not in binary_like + accord_cols]

# Standardize selected columns
scaler = StandardScaler()
df_scaled[cols_to_scale] = scaler.fit_transform(df_scaled[cols_to_scale])

# Show which columns were standardized
print("Columns standardized:", cols_to_scale)

# Show full dataset head (all columns, with standardized values)
print("\nDataFrame with standardized features (head):")
display(df_scaled.head())

"""#6. Modeling

##Regressor
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

"""####Linear"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Features (X) and target (y)
X = df_scaled
y = df['Success_Score']

# Split train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Train linear regression
model = LinearRegression()
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Evaluation
print("R² Score:", r2_score(y_test, y_pred))
print("MSE:", mean_squared_error(y_test, y_pred))

"""Visualize RMSE and R²"""

# 1. Inizializza e addestra il modello
lin_reg = LinearRegression(fit_intercept=True)
lin_reg.fit(X_train, y_train)

# Mostra i coefficienti appresi
print("Model coefficients:", lin_reg.coef_)

# 2. Predizioni sul test set
y_pred = lin_reg.predict(X_test)

# 3. Scatter plot: valori reali vs predetti
plt.figure(figsize=(7, 6))
plt.scatter(y_test, y_pred, alpha=0.5, color="blue")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "r--")  # diagonale perfetta
plt.xlabel("Actual Success Score")
plt.ylabel("Predicted Success Score")
plt.title("Linear Regression: Actual vs Predicted Success Score")
plt.grid(True)
plt.show()

# 4. Calcolo dell'RMSE e R²
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f"RMSE: {rmse:.4f}")
print(f"R²: {r2:.4f}")

# 5. Confronto grafico (bar chart su un subset)
show = 20
pd.DataFrame({
    "y_test": y_test[:show].to_numpy(),
    "y_pred": y_pred[:show]
}).plot(kind="bar", figsize=(12, 6))
plt.title("Comparison of Actual vs Predicted Success Score (first 20 samples)")
plt.xlabel("Sample index")
plt.ylabel("Success Score")
plt.show()

"""####Ensamble"""

# Features (X) and target (y)
X = df_scaled
y = df['Success_Score']

# Split train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Train Random Forest
model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Evaluation
print("R² Score:", r2_score(y_test, y_pred))
print("MSE:", mean_squared_error(y_test, y_pred))

# --- Feature Importance ---
importances = model.feature_importances_
feat_importances = pd.Series(importances, index=X.columns)

# Ordina le feature per importanza
feat_importances_sorted = feat_importances.sort_values(ascending=False)

print("\nTop 10 Features:")
print(feat_importances_sorted.head(20))

# Visualizza graficamente le prime 20
plt.figure(figsize=(10,6))
sns.barplot(x=feat_importances_sorted.head(20).values, y=feat_importances_sorted.head(20).index, palette="viridis") # Changed to horizontal bar plot
plt.title("Feature Importance - Random Forest")
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.tight_layout()
plt.show()

# 1. Inizializza e addestra il modello Random Forest
rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
rf.fit(X_train, y_train)

# 2. Predizioni sul test set
y_pred = rf.predict(X_test)

# 3. Scatter plot: valori reali vs predetti
plt.figure(figsize=(7, 6))
plt.scatter(y_test, y_pred, alpha=0.5, color="green")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "r--")  # diagonale perfetta
plt.xlabel("Actual Success Score")
plt.ylabel("Predicted Success Score")
plt.title("Random Forest: Actual vs Predicted Success Score")
plt.grid(True)
plt.show()

# 4. Calcolo RMSE e R²
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f"RMSE: {rmse:.4f}")
print(f"R²: {r2:.4f}")

# 5. Confronto grafico (bar chart su un subset)
show = 20
pd.DataFrame({
    "y_test": y_test[:show].to_numpy(),
    "y_pred": y_pred[:show]
}).plot(kind="bar", figsize=(12, 6))
plt.title("Random Forest: Actual vs Predicted Success Score (first 20 samples)")
plt.xlabel("Sample index")
plt.ylabel("Success Score")
plt.show()

"""###AutoML"""

# 🔧 Patch for NumPy 2.0 compatibility
if not hasattr(np, "NaN"):
    np.NaN = np.nan

from flaml import AutoML
from sklearn.metrics import mean_squared_error, r2_score

# Initialize AutoML
automl = AutoML()

# Settings
settings = {
    "time_budget": 60,     # max seconds
    "task": "regression",
    "metric": "r2",
    "seed": 42
}

# Train
automl.fit(X_train=X_train, y_train=y_train, **settings)

# Predict
y_pred = automl.predict(X_test)

rmse = np.sqrt(mse)

# Evaluation
print("R²:", r2_score(y_test, y_pred))
print("MSE:", mean_squared_error(y_test, y_pred))
print("RMSE:", rmse)

# Best model
print("Best model:", automl.model.estimator)

"""### **Extra** - Visualizzation - Success Score"""

# Definisci feature (X) e target (y)
X = df_scaled
y = df['Success_Score']

# Split in train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# PCA su un subset (3000 punti per velocità)
pca = PCA(n_components=2, random_state=42)
result_pca = pca.fit_transform(X_train.head(3000))

# Scatter plot colorato in base al target
plt.figure(figsize=(8,6))
plt.scatter(result_pca[:, 0], result_pca[:, 1],
            c=y_train.head(3000), s=5, cmap='viridis')
plt.colorbar(label="Success_Score")
plt.title("PCA visualization of perfumes (first 3000 samples)")
plt.xlabel("PCA-1")
plt.ylabel("PCA-2")
plt.show()

# Definisci feature (X) e target (y)
X = df_scaled
y = df['Success_Score']

# Split in train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# TSNE su un subset (3000 punti per velocità)
tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)
result_tsne = tsne.fit_transform(X_train.head(3000))

# Scatter plot colorato in base al target
plt.figure(figsize=(8,6))
plt.scatter(result_tsne[:, 0], result_tsne[:, 1],
            c=y_train.head(3000), s=5, cmap='viridis')
plt.colorbar(label="Success_Score")
plt.title("t-SNE visualization of perfumes (first 3000 samples)")
plt.xlabel("TSNE-1")
plt.ylabel("TSNE-2")
plt.show()

"""## Classification

Testing classification using **Rating Value** instead of **Success Score**  
for interpretability.

"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold
from scipy.stats import randint

# efine the threshold (median) on Rating Value
threshold = df['Rating Value'].median()

# Create 2 classes based on Rating Value
def classify_rating_binary(rating):
    if rating <= threshold:
        return 0   # low rating
    else:
        return 1   # high rating

df['Rating_Class'] = df['Rating Value'].apply(classify_rating_binary)

# Check the class distribution
print(df['Rating_Class'].value_counts(normalize=True))

"""**Cut at 4 is totally resonable**"""

# Calculate the threshold (median) for Rating Value
threshold = df['Rating Value'].median()
print(f"Soglia di cut: {threshold:.3f}")

# Histogram with cut-off line
plt.figure(figsize=(8,6))
sns.histplot(df['Rating Value'], bins=50, kde=True, color="skyblue")
plt.axvline(threshold, color="red", linestyle="--", label=f"Cut = {threshold:.3f}")
plt.title("Distribuzione Rating Value con soglia per classi binarie")
plt.xlabel("Rating Value")
plt.ylabel("Conteggio")
plt.legend()
plt.show()

# Features (X) e nuovo target (y_class) basato su Rating Value
X = df_scaled
y_class = df['Rating_Class']   # New class

# Split train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y_class, test_size=0.2, random_state=42
)

# Modello
clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
clf.fit(X_train, y_train)

# Predizioni
y_pred = clf.predict(X_test)
y_proba = clf.predict_proba(X_test)[:, 1]  # probabilità classe 1

# Valutazione testuale
print("Classification Report:")
print(classification_report(y_test, y_pred))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# ROC AUC
roc_auc = roc_auc_score(y_test, y_proba)
print(f"ROC AUC: {roc_auc:.3f}")

# Grafico ROC curve
fpr, tpr, _ = roc_curve(y_test, y_proba)
plt.figure(figsize=(6,6))
plt.plot(fpr, tpr, label=f"ROC curve (AUC = {roc_auc:.3f})")
plt.plot([0,1], [0,1], "k--", label="Random")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Random Forest (Rating Value)")
plt.legend()
plt.show()

# Matrice di confusione (grafico)
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=[0,1], yticklabels=[0,1])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Random Forest (Rating Value)")
plt.show()

# Feature importance
importances = clf.feature_importances_
features = X.columns

# Ordina le feature per importanza
feat_importances = pd.Series(importances, index=features).sort_values(ascending=False)

# Stampa le prime 20
print("Top 20 feature importance:")
print(feat_importances.head(20))

# Grafico
plt.figure(figsize=(10,6))
sns.barplot(x=feat_importances.head(20), y=feat_importances.head(20).index, palette="viridis")
plt.title("Top 20 Feature Importances - Rating Value")
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.show()

"""### **Extra** - Experimenting with a Multilayer Perceptron"""

# Features (X) e nuovo target (y_class) basato su Rating Value
X = df_scaled
y_class = df['Rating_Class']   # <-- target binario

# Split train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y_class, test_size=0.2, random_state=42
)

# Modello MLP
mlp = MLPClassifier(
    hidden_layer_sizes=(100,),  # una hidden layer da 100 neuroni
    activation="relu",
    solver="adam",
    batch_size="auto",
    learning_rate="constant",
    max_iter=200,
    shuffle=True,
    random_state=42
)

# Addestramento
mlp.fit(X_train, y_train)

# Predizioni
y_pred = mlp.predict(X_test)
y_proba = mlp.predict_proba(X_test)[:, 1]  # probabilità della classe 1

# Valutazione testuale
print("Classification Report:")
print(classification_report(y_test, y_pred))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# ROC AUC
roc_auc = roc_auc_score(y_test, y_proba)
print(f"ROC AUC: {roc_auc:.3f}")

# Grafico ROC curve
fpr, tpr, _ = roc_curve(y_test, y_proba)
plt.figure(figsize=(6,6))
plt.plot(fpr, tpr, label=f"ROC curve (AUC = {roc_auc:.3f})")
plt.plot([0,1], [0,1], "k--", label="Random")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - MLP Classifier (Rating Value)")
plt.legend()
plt.show()

# Matrice di confusione (grafico)
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=[0,1], yticklabels=[0,1])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - MLP Classifier (Rating Value)")
plt.show()

"""###Hyperparameter Optimization"""

# Features e target
X = df_scaled
y_class = df['Rating_Class']

# Modello base
clf = RandomForestClassifier(random_state=42, n_jobs=-1)

# Spazio di ricerca iperparametri
param_dist = {
    "n_estimators": randint(50, 300),          # numero di alberi
    "max_depth": randint(3, 30),               # profondità massima
    "min_samples_split": randint(2, 20),       # split minimo
    "min_samples_leaf": randint(1, 20),        # minimo campioni foglia
    "max_features": ["sqrt", "log2", None]     # feature selection
}

# Cross-validation stratificata
cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)

# RandomizedSearchCV
random_search = RandomizedSearchCV(
    clf,
    param_distributions=param_dist,
    n_iter=30,                # numero di combinazioni da testare
    scoring="roc_auc",        # metrica principale (puoi usare "accuracy", "f1" ecc.)
    cv=cv,
    verbose=2,
    random_state=42,
    n_jobs=-1
)

# Fit
random_search.fit(X, y_class)

# Migliori parametri
print("Best Parameters:", random_search.best_params_)
print("Best ROC AUC:", random_search.best_score_)

# Usa i migliori parametri trovati
best_params = random_search.best_params_

# Train/Test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y_class, test_size=0.2, stratify=y_class, random_state=42
)

# Crea modello con i parametri ottimizzati
best_model = RandomForestClassifier(
    **best_params,
    random_state=42,
    n_jobs=-1
)

# Fit sul train
best_model.fit(X_train, y_train)

# Predizioni sul test
y_pred = best_model.predict(X_test)
y_proba = best_model.predict_proba(X_test)[:, 1]

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=[0,1], yticklabels=[0,1])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Best Random Forest (Test Set)")
plt.show()

# Classification Report
print("Classification Report (Test Set):")
print(classification_report(y_test, y_pred))

# ROC Curve & AUC
roc_auc = roc_auc_score(y_test, y_proba)
fpr, tpr, _ = roc_curve(y_test, y_proba)

plt.figure(figsize=(6,6))
plt.plot(fpr, tpr, label=f"ROC curve (AUC = {roc_auc:.3f})")
plt.plot([0,1], [0,1], "k--", label="Random")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Best Random Forest (Test Set)")
plt.legend()
plt.show()

"""###AutoML"""

# Patch for NumPy 2.0 compatibility
if not hasattr(np, "NaN"):
    np.NaN = np.nan

from flaml import AutoML
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report

# Initialize AutoML
automl = AutoML()

# Settings per classificazione
settings = {
    "time_budget": 60,     # tempo massimo in secondi
    "task": "classification",
    "metric": "roc_auc",   # metrica principale, puoi usare anche 'accuracy' o 'f1'
    "seed": 42
}

# Train
automl.fit(X_train=X_train, y_train=y_train, **settings)

# Predict
y_pred = automl.predict(X_test)
y_proba = automl.predict_proba(X_test)[:, 1]  # probabilità per classe positiva

# Evaluation
print("Accuracy:", accuracy_score(y_test, y_pred))
print("F1 Score:", f1_score(y_test, y_pred))
print("ROC AUC:", roc_auc_score(y_test, y_proba))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Best model
print("Best model:", automl.model.estimator)

"""### **Extra** - Visualizzation (Rating Value)

**PCA**
"""

X = df_scaled
y_class = df['Rating_Class']

# Split in train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y_class, test_size=0.2, random_state=42
)

# PCA su un subset (3000 punti per velocità)
pca = PCA(n_components=2, random_state=42)
result_pca = pca.fit_transform(X_train.head(3000))

# Scatter plot colorato in base alla classe (0/1)
plt.figure(figsize=(8,6))
plt.scatter(result_pca[:, 0], result_pca[:, 1],
            c=y_train.head(3000), s=5, cmap='coolwarm')  # due colori
plt.colorbar(label="Classe (0 = basso, 1 = alto)")
plt.title("PCA visualization of perfumes (first 3000 samples, binary classes)")
plt.xlabel("PCA-1")
plt.ylabel("PCA-2")
plt.show()

"""***TNSE***"""

X = df_scaled
y_class = df['Rating_Class']

# Split in train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y_class, test_size=0.2, random_state=42
)

# TSNE su un subset (3000 punti per velocità)
tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)
result_tsne = tsne.fit_transform(X_train.head(3000))

# Scatter plot colorato in base alla classe (0/1)
plt.figure(figsize=(8,6))
plt.scatter(result_tsne[:, 0], result_tsne[:, 1],
            c=y_train.head(3000), s=5, cmap='coolwarm')  # coolwarm = due colori
plt.colorbar(label="Classe (0 = basso, 1 = alto)")
plt.title("t-SNE visualization of perfumes (first 3000 samples, binary classes)")
plt.xlabel("TSNE-1")
plt.ylabel("TSNE-2")
plt.show()

"""#7. Extra - Clustering

##Importance of an accord in characterizing the perfume

### TF-IDF Weighted Accord Features

This step transforms the **main fragrance accords** into numerical features using a weighted TF-IDF representation.

1. **Weighted Accord Construction**  
   - Each perfume has up to five main accords, ranked in order of importance.  
   - A weighting scheme was applied: the first accord is repeated 5 times, the second 4 times, down to the fifth accord with weight 1.  
   - This ensures that the **primary accord contributes more strongly** to the feature representation than the less important ones.

2. **TF-IDF Transformation**  
   - TF-IDF (Term Frequency – Inverse Document Frequency) was then applied to the weighted accords.  
   - **TF** captures how prominent an accord is for a specific perfume (influenced by the weighting).  
   - **IDF** downweights very common accords (e.g., “woody”, “floral”) and highlights rarer, more distinctive accords (e.g., “oud”, “leather”).  

3. **Final Representation**  
   - The result is a matrix where each column corresponds to an accord (e.g., *woody*, *vanilla*, *citrus*), and each row corresponds to a perfume.  
   - Each value reflects the **importance of that accord in characterizing the perfume**, relative to the entire dataset.

This approach is meaningful because it captures both **the hierarchical importance of accords within each perfume** and their **distinctiveness across the dataset**, provid
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from mpl_toolkits.mplot3d import Axes3D

# 1. Funzione per pesare gli accordi
def weighted_accords(row):
    accords = []
    if pd.notna(row['mainaccord1']) and row['mainaccord1'] != '':
        accords += [row['mainaccord1']] * 5
    if pd.notna(row['mainaccord2']) and row['mainaccord2'] != '':
        accords += [row['mainaccord2']] * 4
    if pd.notna(row['mainaccord3']) and row['mainaccord3'] != '':
        accords += [row['mainaccord3']] * 3
    if pd.notna(row['mainaccord4']) and row['mainaccord4'] != '':
        accords += [row['mainaccord4']] * 2
    if pd.notna(row['mainaccord5']) and row['mainaccord5'] != '':
        accords += [row['mainaccord5']] * 1
    return " ".join(accords)

# 2. Crea colonna con accordi pesati
df['Weighted_Accords'] = df.apply(weighted_accords, axis=1)

# 3. Calcola TF-IDF
tfidf = TfidfVectorizer(tokenizer=lambda x: x.split())
tfidf_matrix = tfidf.fit_transform(df['Weighted_Accords'])

# 4. Trasforma in DataFrame
tfidf_df = pd.DataFrame(tfidf_matrix.toarray(),
                        columns=tfidf.get_feature_names_out(),
                        index=df.index)

# 5. Output semplice
print("Shape TF-IDF (Weighted Accords):", tfidf_df.shape)
print("Prime 10 feature names:", tfidf.get_feature_names_out()[:10])

print("\nTF-IDF Weighted Accords DataFrame Head:")
display(tfidf_df.head())

# Use the TF-IDF weighted accord features for clustering
try:
    X = tfidf_matrix
except NameError:
    print("Error: tfidf_matrix not found. Please ensure the TF-IDF vectorization step was run.")
    raise

# 1. KMeans Clustering
kmeans = KMeans(n_clusters=10, random_state=42, n_init=10) # Start with 10 clusters, adjust as needed
df['KMeans_Cluster'] = kmeans.fit_predict(X)

# 2. PCA for Visualization
pca_2d = PCA(n_components=2)
X_pca_2d = pca_2d.fit_transform(X.toarray()) # Convert sparse matrix to dense for PCA

df['PCA1'] = X_pca_2d[:, 0]
df['PCA2'] = X_pca_2d[:, 1]

# 3. Visualize KMeans Clusters in 2D
plt.figure(figsize=(12, 8))
sns.scatterplot(x='PCA1', y='PCA2', hue='KMeans_Cluster', data=df, palette='viridis', s=50, alpha=0.6)
plt.title('KMeans Clustering (2D PCA Reduced)')
plt.xlabel('PCA 1')
plt.ylabel('PCA 2')
plt.legend(title='Cluster')
plt.show()

print("\nKMeans Cluster distribution:")
display(df['KMeans_Cluster'].value_counts().sort_index())

# 4. PCA for 3D Visualization
pca_3d = PCA(n_components=3)
X_pca_3d = pca_3d.fit_transform(X.toarray()) # Convert sparse matrix to dense for PCA

df['PCA1_3D'] = X_pca_3d[:, 0]
df['PCA2_3D'] = X_pca_3d[:, 1]
df['PCA3_3D'] = X_pca_3d[:, 2]

# 5. Visualize KMeans Clusters in 3D
fig = plt.figure(figsize=(12, 10))
ax = fig.add_subplot(111, projection='3d')
scatter = ax.scatter(df['PCA1_3D'], df['PCA2_3D'], df['PCA3_3D'], c=df['KMeans_Cluster'], cmap='viridis', alpha=0.6, s=50)
ax.set_title('KMeans Clustering (3D PCA Reduced)')
ax.set_xlabel('PCA 1')
ax.set_ylabel('PCA 2')
ax.set_zlabel('PCA 3')

# Create a color bar for the clusters
legend = ax.legend(*scatter.legend_elements(), title="Cluster")
ax.add_artist(legend)

plt.show()

# Analyze the dominant accords in each KMeans cluster
print("Analyzing KMeans Clusters:")
for cluster_id in sorted(df['KMeans_Cluster'].unique()):
    cluster_df = df[df['KMeans_Cluster'] == cluster_id]
    # Calculate the mean of the TF-IDF scores for the weighted accords within the cluster
    mean_tfidf_scores = tfidf_df.loc[cluster_df.index].mean()
    # Get the top N accords for this cluster
    top_accords = mean_tfidf_scores.nlargest(5) # Get top 5 accords

    print(f"\nCluster {cluster_id}:")
    display(top_accords)

# Create a dictionary to map KMeans cluster IDs to semantic labels
cluster_labels = {
    0: 'Fruttato Dolce',
    1: 'Aromatico Fresco',
    2: 'Floreale Bianco',
    3: 'Speziato Legnoso Caldo',
    4: 'Vanigliato Dolce',
    5: 'Rosa Floreale Muschiato',
    6: 'Verde Acquatico Fresco',
    7: 'Cuoiato Animale Ambrato',
    8: 'Polveroso Muschiato Elegante',
    9: 'Ambrato Orientale Speziato'
}

# Map the cluster IDs to the new labels
df['KMeans_Cluster_Label'] = df['KMeans_Cluster'].map(cluster_labels)

print("DataFrame Head with KMeans Cluster Labels:")
display(df[['Perfume', 'Brand', 'KMeans_Cluster', 'KMeans_Cluster_Label']].head())